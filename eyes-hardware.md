Реализация системы отображенния глаз
====================================

Робот снабжен двумя экранами, используемыми для отображения глаз. 

**Базовые требования**:

1. Способность отображать широкий спектр эмоций (изображение рисуется на уровне ПО).
2. Достаточное быстродействие для отображения базового набора эффектов.
3. Базовый набор эффектов включает полигональную 2D графику (все элементы глаза --- многоугольники, залитые цветом), градиенты (?), смешивание цветов (?).
2. Простота реализации на аппаратном и программном уровне.
5. Минимальная загрузка ЦПУ.


### Текущая реализация

Робот снабжен парой экранов [2.8' ЖК экранов](http://www.hotmcu.com/28-touch-screen-tft-lcd-with-all-interface-p-63.html) на базе технологии TN c контроллером ILI9325.
Экраны имеют разрешение 320x240, подключены через шину SPI, отображаются драйвером [tftfb](https://github.com/notro/fbtft) в пару кадровых буферов (framebuffer).
Частота обновления равна приблизительно 10-20 кадров в секунду и ограничена пропускной способностью SPI.

Текущая версия управляющего ПО представляет пару компонент ROS, которые при помощи библиотеки Qt выводят изображения в кадровые буферы. 
Из поддерживаемых эффектов имеется только перемещение зрачков и моргание. Последнее использовать невозможно из-за отсутствия синхронизации.

Возможностей имеющейся системы явно недостаточно, поэтому
разрабатывается новая версия [компонента управления глаз](eyes-control.md), поддерживающая множество анимаций, разные способы отображения и прочее. 

**Принятые архитектурные решения**:

0. Для отображения глаз используются ЖК экраны.
1. Управляющий компонент монолитен, формирует изображение на два глаза.
2. Управляющий компонент использует библиотеку Qt5.

На настоящий момент эти решения не обсуждаются, их можно рассматривать как спецтребования.

### Обсуждение

Существенную проблему представляет нераспространенность готовых решений по подключению двух полноценных экранов к одному встраиваемому устройству.
Основной видеоинтерфейс один (HDMI, DPI) один и рассчитан на использование с одним экраном. 

Современные IPS экраны (необходимо для приемлемых углов обзора) имеют большое разрешение, обновление их по SPI малореально. Крайне заманчивым выглядит использование аппаратного графического ускорителя и стандартного графического интерфейса (DPI, HDMI). 

Информация о том, как Qt5 обеспечивает графическое ускорение 2-х мерной графики достаточно скудна. 

1. Qt обладает встроенным программным отрисовщиком (`Raster`), в большинстве случаев используется именно он: http://doc.qt.io/qt-5/topics-graphics.html

2. В определенном контексте Qt задействует аппаратной ускорение. При этом набор операций определяется возможностями оборудования/драйвера. Всего есть пять уровней:
    отсутствие аппаратного ускорения, ускорение операций с альфа-каналом, 2х мерная векторная графика, 3D, программируемый конвеер 3D. http://blog.qt.io/blog/2009/03/13/using-hardware-acceleration-for-graphics/
    Недоступные операции заменяются программными, что особенно медленно, если требуется графический контроллер и ЦПУ используют разную память (Non-UMA). 
    Но, вероятно, на нашем оборудовании память общая.

3.  Встраиваемые компьютеры (Rashberry PI, BeagleBoard, TinkerBoard) поддерживают OpenGL ES 2.0, т.е. теоретически они должны предоставлять полный спектр возможностей аппаратного ускорения. 
    Предположительно ускоритель и процессор используют общую память (UMA).

4. Не ясно, как понять, происходит ли в Qt аппаратное ускорение. Очевидно, оно имеет место, при отрисовке на контексты типа `QGLWidget`, в случае 
    `QPixmap` и `QImage` оно имеет только в определенных ситуациях (http://blog.qt.io/blog/2009/12/16/qt-graphics-and-performance-an-overview/ ) при 
    этом не ясно, как влияет выбранный формат данных (для всех ли форматов происходит ускорение, какой формат лучше выбирать). Вероятно, предпочтителен `QPixmap` 
    оптимизированный под конкретное представление на данном устройстве. В любом случае, ускорение будет иметь место только при использовании `QPainter`, любые формы 
    попиксельных операций ускоряться не будут. 

5. Передача изображения через основной графический интерфейс будет выполняться, скорее всего, аппаратно на уровне графического ускорителя. 
    Передача через SPI будет происходить попиксельно, либо через DMA, зависит от реализации драйвера.

Соответственно, наиболее перспективным выглядит использование графического ускорителя как для отрисовки изображений. В этом случае загрузка ЦПУ будет минимальной за счет максимального 
использования возможностей ускорителя.

## Варианты реализации 

### Два экрана на SPI шинах

Текущая реализация, опирающаяся на [tftfb](https://github.com/notro/fbtft) в качестве драйвера.

**Плюсы**:

* Наиболее отработанное решение. 
* Простота программной модели: два кадровых буфера, с которыми либо связывается контекст `QImage` или `QWidget`. В первом случае не требуется развертывание приложения Qt,
    т.к. `QImage` может быть ассоциировано напрямую с областью памяти кадрового буфера. (Пример). Во втором кадровые буферы играют роль экранов.
* На BeagleBoard можно использовать два SPI интерфейса. Однако это уменьшает число доступных UART.

**Минусы**:

* При разрешениях больше 320x240 частота обновления кадров становится практически неприемлемой. Это связано с ограниченной пропускной способность SPI.
    * Частота 16 МГц, разрешение 480x320, 16 бит: не более 6 кадров/c (новые экраны). 
    * Частота 30 МГц, разрешение 320x240, 16 бит, два экрана на одной шине: не более 12 кадров/c (старые экраны).

* Не ясно, осуществляется ли графическое ускорения. Вероятно, при отображении в буфер экрана средствами Qt оно имеет место. 
    В случае отрисовки в `QImage` 16-битного формата ситуация менее ясная.


### Использование HDMI

Существуют готовое решения, способные разделить HDMI сигнал на два экрана: [aliexpress](https://ru.aliexpress.com/item/3-81-inch-1080x1200-AMOLED-display-screenn-3D-VR-head-mounted-display-with-HDMI-to-MIPI/32798181688.html?spm=2114.03010208.3.16.cILH2d&ws_ab_test=searchweb0_0,searchweb201602_2_10152_10065_10151_10208_10068_5310018_10301_10136_10137_10060_10155_10062_437_10154_10056_10055_10054_10059_303_100031_10099_10103_10102_10096_10169_10052_10053_10142_10107_10050_10051_5320018_10084_10083_10080_10082_10081_10110_519_10111_10112_10113_10114_10182_10078_10079_10073_10123_10189_10127_142_10125,searchweb201603_9,ppcSwitch_5&btsid=e4d64333-c083-42bd-9b5d-d1844c2235fc&algo_expid=0458969f-b1c6-4f37-839c-ea2b437f054c-2&algo_pvid=0458969f-b1c6-4f37-839c-ea2b437f054c).
Устройство используется для очков виртуальной реальности (https://www.youtube.com/watch?v=u4TvYW1vDYw ), программно они воспринимаются как единый экран HDMI, его левая половина отображается на 
левом, правая --- на правом. 

**Плюсы**:

* Готовое устройство. 
* OLED экраны.возможностей
* Удобная программная модель: рисуем один кадр, получаем два глаза.

**Минусы**:

* Цена порядка 250-300 $.
* Решение одного производителя.
* Экраны обладают очень большим разрешением 1200x1080 каждый. Однако устройство явно поддерживает другие видео режимы, как минимум 720 строк.

### Использование DPI (параллельный интерфейс)

Наиболее простой и хорошо совместимый интерфейс. Является основным для BeagleBoard, на Rashberry PI 3 отсутствует (не разведен ?). В общем случае проблему снимает преобразователь HDMI -> DPI (https://www.adafruit.com/product/2218).

DPI представляет собой параллельную шину данных (24, 18 или 16 бит), сигналы строковой и кадровой синхронизации. 
Скорость значительно выше SPI, однако частоты все равно составляют десятки МГц.

Для инициализации DPI экранов требуется подать им определнную последовательность команд по SPI или I2C интерфейсу. Используемые нами экраны конфигурируются по SPI. Возможны два варианта инициализации: подвать последовательность команд с компьютера или ввести в систему отдельный микроконтроллер. Последнее решение делает акранный модуль независимым.

Теоретически при помощи аппаратного преобразователя можно разбить вывод контроллера на два экрана.

1. **Покадровая разбивка**: первая половина строк идет на первый экран, вторая на второй. Разделитель сигнала считает строки с начала кадра. 
    Первую половину подает на один экран, затем формирует ложный сигнал вертикальной синхронизации и переключать вывод на другой экран и подает вторую половину строк.

    **Проблемы**: 
    * соблюдение таймингов контроллера экранов (необходимы надлежащие паузы при подача строчной и кадровой синхронизации, см. документация ILI9325 и http://www.nxp.com/wcm_documents/techzones/microcontrollers-techzone/Presentations/graphics.lcd.technologies.pdf ) 
    * Не совсем ясна сложность конфигурации программной части. Согласно https://www.linusakesson.net/hardware/beagleboard/vga.php достаточно просто сконфигурировать видео режим. 
        С другой стороны в может потребоваться указывать длительность пауз, как это описано http://www.nxp.com/wcm_documents/techzones/microcontrollers-techzone/Presentations/graphics.lcd.technologies.pdf
    * поведение экрана в отсутствие сигнала (отсутствие тактового сигнала в частности).  Так первый экран, получает кадр, а затем отключается от шины на время передачи кадра второму экрану. 
        При отсутствии тактирования изображение просто не обновляется (так ведет себя ILI9325 в VSYNC режиме, стр. 40), либо может быть дополнительный сигнал ENABLE (см. тот же ILI9325).
        Однако все может зависеть от модели. 

    **Плюсы**:    
    * Простая программная модель: один экран сверху другого.
    * Полный набор цветов.
    * Задействован основной видео интерфейс, не должно быть проблем с ускорением.

    **Минусы**:
    * Нестандартный режим работы дисплеев. Технически кране рисковый вариант.
    * Сложности может составить настройка нестандартного видео режима (320x480, например)



2. Построчная разбивка: первая половина строки идет на один экран, вторая --- на другой. Принципиального отличия от покадровой разбивки нет, только больше требования к оборудованию разделителя: 
    надо считать не строки, а пиксели.

3. **Попиксельная разбивка**. Нечетные пиксели идут на первый экран, четные --- на второй. Размер отображаемого изображения в два раза больше в длину.

    Техническа реализация возможна следующими способами:
    * Делитель частоты на PCLK в результате чего один экран фиксирует четные, другой нечетные сигналы. Нужны дополнительные схемы согласования на выводы данных. Не очень ясно, что с длительностью VSYNC и HSYNC. Также все отступы (ponch) адо настраивать с учетом, что частота на стороне экрана в два раза меньше.
    * Использование штатной возможности TFP401 выводить два пикселя за такт на разные выходные DPI интерфейсы. 
    * Программная реализация проста и может опираться на альфа-блендинг:
        1. Оба изображения отрисовываются на `QPixmap` удвоенной ширины.
        2. На первое изображение накладывается в режиме SOURCE маска, обнуляющая цвет и альфа-канал на четных строках.
        3. Первое изображение накладывается на второе в режиме SOURCE OVER. 

    **Плюсы**
    * Полноценный цветовой режим
    * Аппаратное ускорение
    * Простая программная реализация

    **Минусы**
    * Разрешение изображение при отрисовке каждого глаза вырастает вдвое

3. Побайтовая разбивка. Экраны работают в 8-битном режиме (RGB233), видео контроллер в 16-битном (RGB565). Возможны два варианта разбивки сигнала:
    * побайтово: старшая часть 16-битного слова передаваемого видео контроллером идет на один экран, младшая --- на другой. Отображается 256 цветов.
    * поканально: старшая часть цветового канала идет на один экран, младшая на другой. Отображается 128 цветов.
    Это технически самый простой вариант разделителя сигнала, надо просто развести разные линии по разным экранам.

    **Проблемы**: 
    * побайтовое разделение требует проведение попиксельных операций для объединения 2-х изображений, наиболее прямая реализация требует использования ЦПУ. ОДнако такие цвета не поддерживаются Qt.
    * в поканальном разделении возможно использование альфа-смешения для совмещения двух изображения. Используемые цвета ограничиваются теми, у которых значение кратно 5 (6-битный цвет в канале после разделения, 64 цвета) или 9 (3-биный цвет, 512 цветов).
        1. Изображения отрисовываются в `QPixmap` спеццветами (значения каналов кратно 5, биты в 0,1 и 5,6 разрядах канала нуевые).
        2. Занчение альфа канала устанавливается в 0.20 (в реальности 0.2040, нужен подбор из-за округления и арифметики с плоавающей точкой GPU).
        3. Выполняется альфа смещение (SOURCE_OVER) первого изображения со вторым. При этом цвета фонового изображения (один глаз)  домножаются на 4/5 ( или  и  к ним прибавляются цвета накладываемого изображения (второй глаз), помноженное на 1/4 (Source Over Blending mode: https://doc.qt.io/archives/qq/qq17-compositionmodes.html). 
    * Проблему спеццветов для поканального разделения можно решить, написав шейдер для объединения изображений.

    **Плюсы**:    
    * Простота электронной части: дорожки разводятся на два экрана.

    **Минусы**:
    * Программная реализация требует попиксельных операций (версия с побайтным разделением)
    * Мало цветов.

## Выводы и предложения

Очень привлекательно выглядит DPI  на базе переходника с HDMI TFP401. Вкупе с дискретным микроконтроллером, подающим инициализирующую последовательность, это превращает пару экранов в завершенное уcтройство, подключаемое через HDMI.

Наиболее хорошо выглядящие режимы --- поканальный и попиксельный. Их технические реализации наиболее просты. Оба допускают быструю реализацию на базе альфа-смешения. Режим поканального разделения наиболее технически прост, однако ограничивает цвета, не дает использовать градиенты. Режим попиксельного разделения больше нагружает GPU, т.к. разрешение изображения по ширине в 2 раза больше. 

**План**
1. Необходимо запустить экран в стандартном режиме. (Сделано)
2. Провериь поканальный режим.
3. Эксперименты с попиксельным.

## Технические детали

### Назначение видеорежима

[KMS инфраструктура](https://wiki.archlinux.org/index.php/kernel_mode_setting):
   * предоставить EDID напрямую через `drm_kms_helper`
   * предоставить EDID напрямую через `drm` (нужна версия ядра выше 4.15)
   * через параметр ядра `video` (обрабатывается модулем `drm`?) --- нет явного указания таймингов, только режим и частота обновления и т.п.

[Прямое взаимодействия с модулем ядра](https://www.linusakesson.net/hardware/beagleboard/vga.php) --- здест пример для `omap` у `BeagleBoard`

[Устаревшие методы для `fbdev`](https://www.systutorials.com/docs/linux/man/8-fbset/) --- не должен работать для соверменной инфраструктуры `drm`/`kms`.

Для `TinkerBoard` есть следующее [обсуждение](https://forum.armbian.com/topic/5416-gpu-driver/). Преимущественно тут про вопрос аппаратного ускорения, но упоминается, что как устанавливать видеорежим непонятно.

Не ясно как осуществить тонкую настройку параметров HDMI (`hdmi_*` параметры в `boot/config.txt` для образов RPI).

## Ссылки по теме:
http://processors.wiki.ti.com/index.php/GPU_Compositing
http://blog.qt.io/blog/2009/11/20/building-qt-to-make-use-of-the-beagle-boards-sgx-gpu/